+quicknet stats-----------------------------------------------------------------------------------------------------+
| Layer                    Input prec.                 Outputs  # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |
|                                (bit)                              x 1       x 1     (kB)                          |
+-------------------------------------------------------------------------------------------------------------------+
| input_10                           -  ((None, 224, 224, 3),)        0         0        0           ?            ? |
| conv2d_26                          -       (-1, 112, 112, 8)        0       216     0.84           0      2709504 |
| depthwise_conv2d                   -        (-1, 56, 56, 64)        0       576     2.25           0      1806336 |
| batch_normalization_210            -        (-1, 56, 56, 64)        0       128     0.50           0            0 |
| quant_conv2d_174                   1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |
| batch_normalization_211            -        (-1, 56, 56, 64)        0       128     0.50           0            0 |
| add_32                             -        (-1, 56, 56, 64)        0         0        0           ?            ? |
| quant_conv2d_175                   1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |
| batch_normalization_212            -        (-1, 56, 56, 64)        0       128     0.50           0            0 |
| add_33                             -        (-1, 56, 56, 64)        0         0        0           ?            ? |
| max_pooling2d_25                   -        (-1, 28, 28, 64)        0         0        0           0            0 |
| quant_conv2d_176                   1        (-1, 28, 28, 64)    36864         0     4.50    28901376            0 |
| batch_normalization_213            -        (-1, 28, 28, 64)        0       128     0.50           0            0 |
| batch_normalization_214            -        (-1, 28, 28, 64)        0       128     0.50           0            0 |
| add_34                             -        (-1, 28, 28, 64)        0         0        0           ?            ? |
| concatenate_127                    -       (-1, 28, 28, 128)        0         0        0           ?            ? |
| quant_conv2d_177                   1       (-1, 28, 28, 128)   147456         0    18.00   115605504            0 |
| batch_normalization_215            -       (-1, 28, 28, 128)        0       256     1.00           0            0 |
| add_35                             -       (-1, 28, 28, 128)        0         0        0           ?            ? |
| quant_conv2d_178                   1       (-1, 28, 28, 128)   147456         0    18.00   115605504            0 |
| batch_normalization_216            -       (-1, 28, 28, 128)        0       256     1.00           0            0 |
| add_36                             -       (-1, 28, 28, 128)        0         0        0           ?            ? |
| max_pooling2d_26                   -       (-1, 14, 14, 128)        0         0        0           0            0 |
| quant_conv2d_179                   1       (-1, 14, 14, 128)   147456         0    18.00    28901376            0 |
| batch_normalization_217            -       (-1, 14, 14, 128)        0       256     1.00           0            0 |
| batch_normalization_218            -       (-1, 14, 14, 128)        0       256     1.00           0            0 |
| add_37                             -       (-1, 14, 14, 128)        0         0        0           ?            ? |
| concatenate_128                    -       (-1, 14, 14, 256)        0         0        0           ?            ? |
| quant_conv2d_180                   1       (-1, 14, 14, 256)   589824         0    72.00   115605504            0 |
| batch_normalization_219            -       (-1, 14, 14, 256)        0       512     2.00           0            0 |
| add_38                             -       (-1, 14, 14, 256)        0         0        0           ?            ? |
| quant_conv2d_181                   1       (-1, 14, 14, 256)   589824         0    72.00   115605504            0 |
| batch_normalization_220            -       (-1, 14, 14, 256)        0       512     2.00           0            0 |
| add_39                             -       (-1, 14, 14, 256)        0         0        0           ?            ? |
| quant_conv2d_182                   1       (-1, 14, 14, 256)   589824         0    72.00   115605504            0 |
| batch_normalization_221            -       (-1, 14, 14, 256)        0       512     2.00           0            0 |
| add_40                             -       (-1, 14, 14, 256)        0         0        0           ?            ? |
| max_pooling2d_27                   -         (-1, 7, 7, 256)        0         0        0           0            0 |
| quant_conv2d_183                   1         (-1, 7, 7, 256)   589824         0    72.00    28901376            0 |
| batch_normalization_222            -         (-1, 7, 7, 256)        0       512     2.00           0            0 |
| batch_normalization_223            -         (-1, 7, 7, 256)        0       512     2.00           0            0 |
| add_41                             -         (-1, 7, 7, 256)        0         0        0           ?            ? |
| concatenate_129                    -         (-1, 7, 7, 512)        0         0        0           ?            ? |
| quant_conv2d_184                   1         (-1, 7, 7, 512)  2359296         0   288.00   115605504            0 |
| batch_normalization_224            -         (-1, 7, 7, 512)        0      1024     4.00           0            0 |
| add_42                             -         (-1, 7, 7, 512)        0         0        0           ?            ? |
| quant_conv2d_185                   1         (-1, 7, 7, 512)  2359296         0   288.00   115605504            0 |
| batch_normalization_225            -         (-1, 7, 7, 512)        0      1024     4.00           0            0 |
| add_43                             -         (-1, 7, 7, 512)        0         0        0           ?            ? |
| quant_conv2d_186                   1         (-1, 7, 7, 512)  2359296         0   288.00   115605504            0 |
| batch_normalization_226            -         (-1, 7, 7, 512)        0      1024     4.00           0            0 |
| add_44                             -         (-1, 7, 7, 512)        0         0        0           ?            ? |
| activation_34                      -         (-1, 7, 7, 512)        0         0        0           ?            ? |
| average_pooling2d_12               -         (-1, 1, 1, 512)        0         0        0           0            0 |
| flatten_9                          -               (-1, 512)        0         0        0           0            0 |
| dense_8                            -              (-1, 1000)        0    513000  2003.91           0       512000 |
| activation_35                      -              (-1, 1000)        0         0        0           ?            ? |
+-------------------------------------------------------------------------------------------------------------------+
| Total                                                         9990144    521088  3255.00  1242759168      5027840 |
+-------------------------------------------------------------------------------------------------------------------+
+quicknet summary-----------------------------+
| Total params                      10.5 M    |
| Trainable params                  10.5 M    |
| Non-trainable params              7.3 k     |
| Model size                        3.18 MiB  |
| Model size (8-bit FP weights)     1.69 MiB  |
| Float-32 Equivalent               40.10 MiB |
| Compression Ratio of Memory       0.08      |
| Number of MACs                    1.25 B    |
| Ratio of MACs that are binarized  0.9960    |
+---------------------------------------------+
