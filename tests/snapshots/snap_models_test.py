# -*- coding: utf-8 -*-
# snapshottest: v1 - https://goo.gl/zC4yUc
from __future__ import unicode_literals

from snapshottest import Snapshot


snapshots = Snapshot()

snapshots['test_compare_model_summary[TrainBinaryAlexNet] 1'] = b'+binary_alexnet stats----------------------------------------------------------------------------------------------+\n| Layer                  Input prec.                 Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                              (bit)                               x 1       x 1     (kB)                          |\n+------------------------------------------------------------------------------------------------------------------+\n| input_1                          -  ((None, 224, 224, 3),)         0         0        0           ?            ? |\n| quant_conv2d                     -        (-1, 56, 56, 64)     23232         0     2.84           0     72855552 |\n| max_pooling2d                    -        (-1, 27, 27, 64)         0         0        0           0            0 |\n| batch_normalization              -        (-1, 27, 27, 64)         0       192     0.75           0            0 |\n| quant_conv2d_1                   1       (-1, 27, 27, 192)    307200         0    37.50   223948800            0 |\n| max_pooling2d_1                  -       (-1, 13, 13, 192)         0         0        0           0            0 |\n| batch_normalization_1            -       (-1, 13, 13, 192)         0       576     2.25           0            0 |\n| quant_conv2d_2                   1       (-1, 13, 13, 384)    663552         0    81.00   112140288            0 |\n| batch_normalization_2            -       (-1, 13, 13, 384)         0      1152     4.50           0            0 |\n| quant_conv2d_3                   1       (-1, 13, 13, 384)   1327104         0   162.00   224280576            0 |\n| batch_normalization_3            -       (-1, 13, 13, 384)         0      1152     4.50           0            0 |\n| quant_conv2d_4                   1       (-1, 13, 13, 256)    884736         0   108.00   149520384            0 |\n| max_pooling2d_2                  -         (-1, 6, 6, 256)         0         0        0           0            0 |\n| batch_normalization_4            -         (-1, 6, 6, 256)         0       768     3.00           0            0 |\n| flatten                          -              (-1, 9216)         0         0        0           0            0 |\n| quant_dense                      1              (-1, 4096)  37748736         0  4608.00    37748736            0 |\n| batch_normalization_5            -              (-1, 4096)         0     12288    48.00           0            0 |\n| quant_dense_1                    1              (-1, 4096)  16777216         0  2048.00    16777216            0 |\n| batch_normalization_6            -              (-1, 4096)         0     12288    48.00           0            0 |\n| quant_dense_2                    1               (-1, 102)    417792         0    51.00      417792            0 |\n| batch_normalization_7            -               (-1, 102)         0       306     1.20           0            0 |\n| activation                       -               (-1, 102)         0         0        0           ?            ? |\n+------------------------------------------------------------------------------------------------------------------+\n| Total                                                       58149568     28722  7210.53   764833792     72855552 |\n+------------------------------------------------------------------------------------------------------------------+\n+binary_alexnet summary-----------------------+\n| Total params                      58.2 M    |\n| Trainable params                  58.2 M    |\n| Non-trainable params              19.1 k    |\n| Model size:                       7.04 MB   |\n| Float-32 Equivalent               221.93 MB |\n| Compression Ratio of Memory       0.03      |\n| Number of MACs                    838 M     |\n| Ratio of MACs that are binarized  0.9130    |\n+---------------------------------------------+\nDry run: Not starting training!\n'

snapshots['test_compare_model_summary[TrainXNORNet] 1'] = b'+xnornet stats-----------------------------------------------------------------------------------------------------+\n| Layer                  Input prec.                 Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                              (bit)                               x 1       x 1     (kB)                          |\n+------------------------------------------------------------------------------------------------------------------+\n| input_1                          -  ((None, 224, 224, 3),)         0         0        0           ?            ? |\n| conv2d                           -        (-1, 56, 56, 96)         0     34848   136.12           0    109283328 |\n| batch_normalization              -        (-1, 56, 56, 96)         0       288     1.12           0            0 |\n| activation                       -        (-1, 56, 56, 96)         0         0        0           ?            ? |\n| max_pooling2d                    -        (-1, 27, 27, 96)         0         0        0           0            0 |\n| batch_normalization_1            -        (-1, 27, 27, 96)         0       288     1.12           0            0 |\n| quant_conv2d                     1       (-1, 27, 27, 256)    614400         0    75.00   447897600            0 |\n| max_pooling2d_1                  -       (-1, 13, 13, 256)         0         0        0           0            0 |\n| batch_normalization_2            -       (-1, 13, 13, 256)         0       768     3.00           0            0 |\n| quant_conv2d_1                   1       (-1, 13, 13, 384)    884736         0   108.00   149520384            0 |\n| batch_normalization_3            -       (-1, 13, 13, 384)         0      1152     4.50           0            0 |\n| quant_conv2d_2                   1       (-1, 13, 13, 384)   1327104         0   162.00   224280576            0 |\n| batch_normalization_4            -       (-1, 13, 13, 384)         0      1152     4.50           0            0 |\n| quant_conv2d_3                   1       (-1, 13, 13, 256)    884736         0   108.00   149520384            0 |\n| max_pooling2d_2                  -         (-1, 6, 6, 256)         0         0        0           0            0 |\n| batch_normalization_5            -         (-1, 6, 6, 256)         0       768     3.00           0            0 |\n| quant_conv2d_4                   1        (-1, 1, 1, 4096)  37748736         0  4608.00    37748736            0 |\n| batch_normalization_6            -        (-1, 1, 1, 4096)         0     12288    48.00           0            0 |\n| quant_conv2d_5                   1        (-1, 1, 1, 4096)  16777216         0  2048.00    16777216            0 |\n| batch_normalization_7            -        (-1, 1, 1, 4096)         0     12288    48.00           0            0 |\n| activation_1                     -        (-1, 1, 1, 4096)         0         0        0           ?            ? |\n| flatten                          -              (-1, 4096)         0         0        0           0            0 |\n| dense                            -               (-1, 102)         0    417792  1632.00           0       417792 |\n| activation_2                     -               (-1, 102)         0         0        0           ?            ? |\n+------------------------------------------------------------------------------------------------------------------+\n| Total                                                       58236928    481632  8990.38  1025744896    109701120 |\n+------------------------------------------------------------------------------------------------------------------+\n+xnornet summary------------------------------+\n| Total params                      58.7 M    |\n| Trainable params                  58.7 M    |\n| Non-trainable params              19.3 k    |\n| Model size:                       8.78 MB   |\n| Float-32 Equivalent               223.99 MB |\n| Compression Ratio of Memory       0.04      |\n| Number of MACs                    1.14 B    |\n| Ratio of MACs that are binarized  0.9034    |\n+---------------------------------------------+\nDry run: Not starting training!\n'

snapshots['test_compare_model_summary[TrainBiRealNet] 1'] = b'+birealnet18 stats----------------------------------------------------------------------------------------------------+\n| Layer                     Input prec.                 Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                                 (bit)                               x 1       x 1     (kB)                          |\n+---------------------------------------------------------------------------------------------------------------------+\n| input_1                             -  ((None, 224, 224, 3),)         0         0        0           ?            ? |\n| conv2d                              -      (-1, 112, 112, 64)         0      9408    36.75           0    118013952 |\n| batch_normalization                 -      (-1, 112, 112, 64)         0       256     1.00           0            0 |\n| max_pooling2d                       -        (-1, 56, 56, 64)         0         0        0           0            0 |\n| quant_conv2d                        1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| batch_normalization_1               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| add                                 -        (-1, 56, 56, 64)         0         0        0           ?            ? |\n| quant_conv2d_1                      1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| batch_normalization_2               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| add_1                               -        (-1, 56, 56, 64)         0         0        0           ?            ? |\n| quant_conv2d_2                      1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| batch_normalization_3               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| add_2                               -        (-1, 56, 56, 64)         0         0        0           ?            ? |\n| quant_conv2d_3                      1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| batch_normalization_4               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| add_3                               -        (-1, 56, 56, 64)         0         0        0           ?            ? |\n| average_pooling2d                   -        (-1, 28, 28, 64)         0         0        0           0            0 |\n| quant_conv2d_4                      1       (-1, 28, 28, 128)     73728         0     9.00    57802752            0 |\n| conv2d_1                            -       (-1, 28, 28, 128)         0      8192    32.00           0      6422528 |\n| batch_normalization_6               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| batch_normalization_5               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| add_4                               -       (-1, 28, 28, 128)         0         0        0           ?            ? |\n| quant_conv2d_5                      1       (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n| batch_normalization_7               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| add_5                               -       (-1, 28, 28, 128)         0         0        0           ?            ? |\n| quant_conv2d_6                      1       (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n| batch_normalization_8               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| add_6                               -       (-1, 28, 28, 128)         0         0        0           ?            ? |\n| quant_conv2d_7                      1       (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n| batch_normalization_9               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| add_7                               -       (-1, 28, 28, 128)         0         0        0           ?            ? |\n| average_pooling2d_1                 -       (-1, 14, 14, 128)         0         0        0           0            0 |\n| quant_conv2d_8                      1       (-1, 14, 14, 256)    294912         0    36.00    57802752            0 |\n| conv2d_2                            -       (-1, 14, 14, 256)         0     32768   128.00           0      6422528 |\n| batch_normalization_11              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| batch_normalization_10              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| add_8                               -       (-1, 14, 14, 256)         0         0        0           ?            ? |\n| quant_conv2d_9                      1       (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n| batch_normalization_12              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| add_9                               -       (-1, 14, 14, 256)         0         0        0           ?            ? |\n| quant_conv2d_10                     1       (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n| batch_normalization_13              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| add_10                              -       (-1, 14, 14, 256)         0         0        0           ?            ? |\n| quant_conv2d_11                     1       (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n| batch_normalization_14              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| add_11                              -       (-1, 14, 14, 256)         0         0        0           ?            ? |\n| average_pooling2d_2                 -         (-1, 7, 7, 256)         0         0        0           0            0 |\n| quant_conv2d_12                     1         (-1, 7, 7, 512)   1179648         0   144.00    57802752            0 |\n| conv2d_3                            -         (-1, 7, 7, 512)         0    131072   512.00           0      6422528 |\n| batch_normalization_16              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| batch_normalization_15              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| add_12                              -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| quant_conv2d_13                     1         (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n| batch_normalization_17              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| add_13                              -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| quant_conv2d_14                     1         (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n| batch_normalization_18              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| add_14                              -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| quant_conv2d_15                     1         (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n| batch_normalization_19              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| add_15                              -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| global_average_pooling2d            -               (-1, 512)         0         0        0           ?            ? |\n| dense                               -               (-1, 102)         0     52326   204.40           0        52224 |\n+---------------------------------------------------------------------------------------------------------------------+\n| Total                                                          10985472    252966  2329.15  1676279808    137333760 |\n+---------------------------------------------------------------------------------------------------------------------+\n+birealnet18 summary-------------------------+\n| Total params                      11.2 M   |\n| Trainable params                  11.2 M   |\n| Non-trainable params              9.60 k   |\n| Model size:                       2.27 MB  |\n| Float-32 Equivalent               42.87 MB |\n| Compression Ratio of Memory       0.05     |\n| Number of MACs                    1.81 B   |\n| Ratio of MACs that are binarized  0.9243   |\n+--------------------------------------------+\nDry run: Not starting training!\n'

snapshots['test_compare_model_summary[TrainBinaryDenseNet28] 1'] = b'+binary_densenet28 stats---------------------------------------------------------------------------------------------+\n| Layer                     Input prec.                 Outputs  # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                                 (bit)                              x 1       x 1     (kB)                          |\n+--------------------------------------------------------------------------------------------------------------------+\n| input_1                             -  ((None, 224, 224, 3),)        0         0        0           ?            ? |\n| conv2d                              -      (-1, 112, 112, 64)        0      9408    36.75           0    118013952 |\n| batch_normalization                 -      (-1, 112, 112, 64)        0       256     1.00           0            0 |\n| activation                          -      (-1, 112, 112, 64)        0         0        0           ?            ? |\n| max_pooling2d                       -        (-1, 56, 56, 64)        0         0        0           0            0 |\n| batch_normalization_1               -        (-1, 56, 56, 64)        0       256     1.00           0            0 |\n| quant_conv2d                        1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |\n| concatenate                         -       (-1, 56, 56, 128)        0         0        0           ?            ? |\n| batch_normalization_2               -       (-1, 56, 56, 128)        0       512     2.00           0            0 |\n| quant_conv2d_1                      1        (-1, 56, 56, 64)    73728         0     9.00   231211008            0 |\n| concatenate_1                       -       (-1, 56, 56, 192)        0         0        0           ?            ? |\n| batch_normalization_3               -       (-1, 56, 56, 192)        0       768     3.00           0            0 |\n| quant_conv2d_2                      1        (-1, 56, 56, 64)   110592         0    13.50   346816512            0 |\n| concatenate_2                       -       (-1, 56, 56, 256)        0         0        0           ?            ? |\n| batch_normalization_4               -       (-1, 56, 56, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_3                      1        (-1, 56, 56, 64)   147456         0    18.00   462422016            0 |\n| concatenate_3                       -       (-1, 56, 56, 320)        0         0        0           ?            ? |\n| batch_normalization_5               -       (-1, 56, 56, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_4                      1        (-1, 56, 56, 64)   184320         0    22.50   578027520            0 |\n| concatenate_4                       -       (-1, 56, 56, 384)        0         0        0           ?            ? |\n| batch_normalization_6               -       (-1, 56, 56, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_5                      1        (-1, 56, 56, 64)   221184         0    27.00   693633024            0 |\n| concatenate_5                       -       (-1, 56, 56, 448)        0         0        0           ?            ? |\n| batch_normalization_7               -       (-1, 56, 56, 448)        0      1792     7.00           0            0 |\n| max_pooling2d_1                     -       (-1, 28, 28, 448)        0         0        0           0            0 |\n| activation_1                        -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n| conv2d_1                            -       (-1, 28, 28, 160)        0     71680   280.00           0     56197120 |\n| batch_normalization_8               -       (-1, 28, 28, 160)        0       640     2.50           0            0 |\n| quant_conv2d_6                      1        (-1, 28, 28, 64)    92160         0    11.25    72253440            0 |\n| concatenate_6                       -       (-1, 28, 28, 224)        0         0        0           ?            ? |\n| batch_normalization_9               -       (-1, 28, 28, 224)        0       896     3.50           0            0 |\n| quant_conv2d_7                      1        (-1, 28, 28, 64)   129024         0    15.75   101154816            0 |\n| concatenate_7                       -       (-1, 28, 28, 288)        0         0        0           ?            ? |\n| batch_normalization_10              -       (-1, 28, 28, 288)        0      1152     4.50           0            0 |\n| quant_conv2d_8                      1        (-1, 28, 28, 64)   165888         0    20.25   130056192            0 |\n| concatenate_8                       -       (-1, 28, 28, 352)        0         0        0           ?            ? |\n| batch_normalization_11              -       (-1, 28, 28, 352)        0      1408     5.50           0            0 |\n| quant_conv2d_9                      1        (-1, 28, 28, 64)   202752         0    24.75   158957568            0 |\n| concatenate_9                       -       (-1, 28, 28, 416)        0         0        0           ?            ? |\n| batch_normalization_12              -       (-1, 28, 28, 416)        0      1664     6.50           0            0 |\n| quant_conv2d_10                     1        (-1, 28, 28, 64)   239616         0    29.25   187858944            0 |\n| concatenate_10                      -       (-1, 28, 28, 480)        0         0        0           ?            ? |\n| batch_normalization_13              -       (-1, 28, 28, 480)        0      1920     7.50           0            0 |\n| quant_conv2d_11                     1        (-1, 28, 28, 64)   276480         0    33.75   216760320            0 |\n| concatenate_11                      -       (-1, 28, 28, 544)        0         0        0           ?            ? |\n| batch_normalization_14              -       (-1, 28, 28, 544)        0      2176     8.50           0            0 |\n| max_pooling2d_2                     -       (-1, 14, 14, 544)        0         0        0           0            0 |\n| activation_2                        -       (-1, 14, 14, 544)        0         0        0           ?            ? |\n| conv2d_2                            -       (-1, 14, 14, 192)        0    104448   408.00           0     20471808 |\n| batch_normalization_15              -       (-1, 14, 14, 192)        0       768     3.00           0            0 |\n| quant_conv2d_12                     1        (-1, 14, 14, 64)   110592         0    13.50    21676032            0 |\n| concatenate_12                      -       (-1, 14, 14, 256)        0         0        0           ?            ? |\n| batch_normalization_16              -       (-1, 14, 14, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_13                     1        (-1, 14, 14, 64)   147456         0    18.00    28901376            0 |\n| concatenate_13                      -       (-1, 14, 14, 320)        0         0        0           ?            ? |\n| batch_normalization_17              -       (-1, 14, 14, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_14                     1        (-1, 14, 14, 64)   184320         0    22.50    36126720            0 |\n| concatenate_14                      -       (-1, 14, 14, 384)        0         0        0           ?            ? |\n| batch_normalization_18              -       (-1, 14, 14, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_15                     1        (-1, 14, 14, 64)   221184         0    27.00    43352064            0 |\n| concatenate_15                      -       (-1, 14, 14, 448)        0         0        0           ?            ? |\n| batch_normalization_19              -       (-1, 14, 14, 448)        0      1792     7.00           0            0 |\n| quant_conv2d_16                     1        (-1, 14, 14, 64)   258048         0    31.50    50577408            0 |\n| concatenate_16                      -       (-1, 14, 14, 512)        0         0        0           ?            ? |\n| batch_normalization_20              -       (-1, 14, 14, 512)        0      2048     8.00           0            0 |\n| quant_conv2d_17                     1        (-1, 14, 14, 64)   294912         0    36.00    57802752            0 |\n| concatenate_17                      -       (-1, 14, 14, 576)        0         0        0           ?            ? |\n| batch_normalization_21              -       (-1, 14, 14, 576)        0      2304     9.00           0            0 |\n| max_pooling2d_3                     -         (-1, 7, 7, 576)        0         0        0           0            0 |\n| activation_3                        -         (-1, 7, 7, 576)        0         0        0           ?            ? |\n| conv2d_3                            -         (-1, 7, 7, 256)        0    147456   576.00           0      7225344 |\n| batch_normalization_22              -         (-1, 7, 7, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_18                     1          (-1, 7, 7, 64)   147456         0    18.00     7225344            0 |\n| concatenate_18                      -         (-1, 7, 7, 320)        0         0        0           ?            ? |\n| batch_normalization_23              -         (-1, 7, 7, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_19                     1          (-1, 7, 7, 64)   184320         0    22.50     9031680            0 |\n| concatenate_19                      -         (-1, 7, 7, 384)        0         0        0           ?            ? |\n| batch_normalization_24              -         (-1, 7, 7, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_20                     1          (-1, 7, 7, 64)   221184         0    27.00    10838016            0 |\n| concatenate_20                      -         (-1, 7, 7, 448)        0         0        0           ?            ? |\n| batch_normalization_25              -         (-1, 7, 7, 448)        0      1792     7.00           0            0 |\n| quant_conv2d_21                     1          (-1, 7, 7, 64)   258048         0    31.50    12644352            0 |\n| concatenate_21                      -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n| batch_normalization_26              -         (-1, 7, 7, 512)        0      2048     8.00           0            0 |\n| quant_conv2d_22                     1          (-1, 7, 7, 64)   294912         0    36.00    14450688            0 |\n| concatenate_22                      -         (-1, 7, 7, 576)        0         0        0           ?            ? |\n| batch_normalization_27              -         (-1, 7, 7, 576)        0      2304     9.00           0            0 |\n| activation_4                        -         (-1, 7, 7, 576)        0         0        0           ?            ? |\n| global_average_pooling2d            -               (-1, 576)        0         0        0           ?            ? |\n| dense                               -               (-1, 102)        0     58854   229.90           0        58752 |\n+--------------------------------------------------------------------------------------------------------------------+\n| Total                                                          4202496    429862  2192.15  3587383296    201966976 |\n+--------------------------------------------------------------------------------------------------------------------+\n+binary_densenet28 summary-------------------+\n| Total params                      4.63 M   |\n| Trainable params                  4.61 M   |\n| Non-trainable params              19.0 k   |\n| Model size:                       2.14 MB  |\n| Float-32 Equivalent               17.67 MB |\n| Compression Ratio of Memory       0.12     |\n| Number of MACs                    3.79 B   |\n| Ratio of MACs that are binarized  0.9467   |\n+--------------------------------------------+\nDry run: Not starting training!\n'

snapshots['test_compare_model_summary[TrainBinaryDenseNet37] 1'] = b'+binary_densenet37 stats---------------------------------------------------------------------------------------------+\n| Layer                     Input prec.                 Outputs  # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                                 (bit)                              x 1       x 1     (kB)                          |\n+--------------------------------------------------------------------------------------------------------------------+\n| input_1                             -  ((None, 224, 224, 3),)        0         0        0           ?            ? |\n| conv2d                              -      (-1, 112, 112, 64)        0      9408    36.75           0    118013952 |\n| batch_normalization                 -      (-1, 112, 112, 64)        0       256     1.00           0            0 |\n| activation                          -      (-1, 112, 112, 64)        0         0        0           ?            ? |\n| max_pooling2d                       -        (-1, 56, 56, 64)        0         0        0           0            0 |\n| batch_normalization_1               -        (-1, 56, 56, 64)        0       256     1.00           0            0 |\n| quant_conv2d                        1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |\n| concatenate                         -       (-1, 56, 56, 128)        0         0        0           ?            ? |\n| batch_normalization_2               -       (-1, 56, 56, 128)        0       512     2.00           0            0 |\n| quant_conv2d_1                      1        (-1, 56, 56, 64)    73728         0     9.00   231211008            0 |\n| concatenate_1                       -       (-1, 56, 56, 192)        0         0        0           ?            ? |\n| batch_normalization_3               -       (-1, 56, 56, 192)        0       768     3.00           0            0 |\n| quant_conv2d_2                      1        (-1, 56, 56, 64)   110592         0    13.50   346816512            0 |\n| concatenate_2                       -       (-1, 56, 56, 256)        0         0        0           ?            ? |\n| batch_normalization_4               -       (-1, 56, 56, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_3                      1        (-1, 56, 56, 64)   147456         0    18.00   462422016            0 |\n| concatenate_3                       -       (-1, 56, 56, 320)        0         0        0           ?            ? |\n| batch_normalization_5               -       (-1, 56, 56, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_4                      1        (-1, 56, 56, 64)   184320         0    22.50   578027520            0 |\n| concatenate_4                       -       (-1, 56, 56, 384)        0         0        0           ?            ? |\n| batch_normalization_6               -       (-1, 56, 56, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_5                      1        (-1, 56, 56, 64)   221184         0    27.00   693633024            0 |\n| concatenate_5                       -       (-1, 56, 56, 448)        0         0        0           ?            ? |\n| batch_normalization_7               -       (-1, 56, 56, 448)        0      1792     7.00           0            0 |\n| max_pooling2d_1                     -       (-1, 28, 28, 448)        0         0        0           0            0 |\n| activation_1                        -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n| conv2d_1                            -       (-1, 28, 28, 128)        0     57344   224.00           0     44957696 |\n| batch_normalization_8               -       (-1, 28, 28, 128)        0       512     2.00           0            0 |\n| quant_conv2d_6                      1        (-1, 28, 28, 64)    73728         0     9.00    57802752            0 |\n| concatenate_6                       -       (-1, 28, 28, 192)        0         0        0           ?            ? |\n| batch_normalization_9               -       (-1, 28, 28, 192)        0       768     3.00           0            0 |\n| quant_conv2d_7                      1        (-1, 28, 28, 64)   110592         0    13.50    86704128            0 |\n| concatenate_7                       -       (-1, 28, 28, 256)        0         0        0           ?            ? |\n| batch_normalization_10              -       (-1, 28, 28, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_8                      1        (-1, 28, 28, 64)   147456         0    18.00   115605504            0 |\n| concatenate_8                       -       (-1, 28, 28, 320)        0         0        0           ?            ? |\n| batch_normalization_11              -       (-1, 28, 28, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_9                      1        (-1, 28, 28, 64)   184320         0    22.50   144506880            0 |\n| concatenate_9                       -       (-1, 28, 28, 384)        0         0        0           ?            ? |\n| batch_normalization_12              -       (-1, 28, 28, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_10                     1        (-1, 28, 28, 64)   221184         0    27.00   173408256            0 |\n| concatenate_10                      -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n| batch_normalization_13              -       (-1, 28, 28, 448)        0      1792     7.00           0            0 |\n| quant_conv2d_11                     1        (-1, 28, 28, 64)   258048         0    31.50   202309632            0 |\n| concatenate_11                      -       (-1, 28, 28, 512)        0         0        0           ?            ? |\n| batch_normalization_14              -       (-1, 28, 28, 512)        0      2048     8.00           0            0 |\n| quant_conv2d_12                     1        (-1, 28, 28, 64)   294912         0    36.00   231211008            0 |\n| concatenate_12                      -       (-1, 28, 28, 576)        0         0        0           ?            ? |\n| batch_normalization_15              -       (-1, 28, 28, 576)        0      2304     9.00           0            0 |\n| quant_conv2d_13                     1        (-1, 28, 28, 64)   331776         0    40.50   260112384            0 |\n| concatenate_13                      -       (-1, 28, 28, 640)        0         0        0           ?            ? |\n| batch_normalization_16              -       (-1, 28, 28, 640)        0      2560    10.00           0            0 |\n| max_pooling2d_2                     -       (-1, 14, 14, 640)        0         0        0           0            0 |\n| activation_2                        -       (-1, 14, 14, 640)        0         0        0           ?            ? |\n| conv2d_2                            -       (-1, 14, 14, 192)        0    122880   480.00           0     24084480 |\n| batch_normalization_17              -       (-1, 14, 14, 192)        0       768     3.00           0            0 |\n| quant_conv2d_14                     1        (-1, 14, 14, 64)   110592         0    13.50    21676032            0 |\n| concatenate_14                      -       (-1, 14, 14, 256)        0         0        0           ?            ? |\n| batch_normalization_18              -       (-1, 14, 14, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_15                     1        (-1, 14, 14, 64)   147456         0    18.00    28901376            0 |\n| concatenate_15                      -       (-1, 14, 14, 320)        0         0        0           ?            ? |\n| batch_normalization_19              -       (-1, 14, 14, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_16                     1        (-1, 14, 14, 64)   184320         0    22.50    36126720            0 |\n| concatenate_16                      -       (-1, 14, 14, 384)        0         0        0           ?            ? |\n| batch_normalization_20              -       (-1, 14, 14, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_17                     1        (-1, 14, 14, 64)   221184         0    27.00    43352064            0 |\n| concatenate_17                      -       (-1, 14, 14, 448)        0         0        0           ?            ? |\n| batch_normalization_21              -       (-1, 14, 14, 448)        0      1792     7.00           0            0 |\n| quant_conv2d_18                     1        (-1, 14, 14, 64)   258048         0    31.50    50577408            0 |\n| concatenate_18                      -       (-1, 14, 14, 512)        0         0        0           ?            ? |\n| batch_normalization_22              -       (-1, 14, 14, 512)        0      2048     8.00           0            0 |\n| quant_conv2d_19                     1        (-1, 14, 14, 64)   294912         0    36.00    57802752            0 |\n| concatenate_19                      -       (-1, 14, 14, 576)        0         0        0           ?            ? |\n| batch_normalization_23              -       (-1, 14, 14, 576)        0      2304     9.00           0            0 |\n| quant_conv2d_20                     1        (-1, 14, 14, 64)   331776         0    40.50    65028096            0 |\n| concatenate_20                      -       (-1, 14, 14, 640)        0         0        0           ?            ? |\n| batch_normalization_24              -       (-1, 14, 14, 640)        0      2560    10.00           0            0 |\n| quant_conv2d_21                     1        (-1, 14, 14, 64)   368640         0    45.00    72253440            0 |\n| concatenate_21                      -       (-1, 14, 14, 704)        0         0        0           ?            ? |\n| batch_normalization_25              -       (-1, 14, 14, 704)        0      2816    11.00           0            0 |\n| quant_conv2d_22                     1        (-1, 14, 14, 64)   405504         0    49.50    79478784            0 |\n| concatenate_22                      -       (-1, 14, 14, 768)        0         0        0           ?            ? |\n| batch_normalization_26              -       (-1, 14, 14, 768)        0      3072    12.00           0            0 |\n| quant_conv2d_23                     1        (-1, 14, 14, 64)   442368         0    54.00    86704128            0 |\n| concatenate_23                      -       (-1, 14, 14, 832)        0         0        0           ?            ? |\n| batch_normalization_27              -       (-1, 14, 14, 832)        0      3328    13.00           0            0 |\n| quant_conv2d_24                     1        (-1, 14, 14, 64)   479232         0    58.50    93929472            0 |\n| concatenate_24                      -       (-1, 14, 14, 896)        0         0        0           ?            ? |\n| batch_normalization_28              -       (-1, 14, 14, 896)        0      3584    14.00           0            0 |\n| quant_conv2d_25                     1        (-1, 14, 14, 64)   516096         0    63.00   101154816            0 |\n| concatenate_25                      -       (-1, 14, 14, 960)        0         0        0           ?            ? |\n| batch_normalization_29              -       (-1, 14, 14, 960)        0      3840    15.00           0            0 |\n| max_pooling2d_3                     -         (-1, 7, 7, 960)        0         0        0           0            0 |\n| activation_3                        -         (-1, 7, 7, 960)        0         0        0           ?            ? |\n| conv2d_3                            -         (-1, 7, 7, 256)        0    245760   960.00           0     12042240 |\n| batch_normalization_30              -         (-1, 7, 7, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_26                     1          (-1, 7, 7, 64)   147456         0    18.00     7225344            0 |\n| concatenate_26                      -         (-1, 7, 7, 320)        0         0        0           ?            ? |\n| batch_normalization_31              -         (-1, 7, 7, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_27                     1          (-1, 7, 7, 64)   184320         0    22.50     9031680            0 |\n| concatenate_27                      -         (-1, 7, 7, 384)        0         0        0           ?            ? |\n| batch_normalization_32              -         (-1, 7, 7, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_28                     1          (-1, 7, 7, 64)   221184         0    27.00    10838016            0 |\n| concatenate_28                      -         (-1, 7, 7, 448)        0         0        0           ?            ? |\n| batch_normalization_33              -         (-1, 7, 7, 448)        0      1792     7.00           0            0 |\n| quant_conv2d_29                     1          (-1, 7, 7, 64)   258048         0    31.50    12644352            0 |\n| concatenate_29                      -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n| batch_normalization_34              -         (-1, 7, 7, 512)        0      2048     8.00           0            0 |\n| quant_conv2d_30                     1          (-1, 7, 7, 64)   294912         0    36.00    14450688            0 |\n| concatenate_30                      -         (-1, 7, 7, 576)        0         0        0           ?            ? |\n| batch_normalization_35              -         (-1, 7, 7, 576)        0      2304     9.00           0            0 |\n| quant_conv2d_31                     1          (-1, 7, 7, 64)   331776         0    40.50    16257024            0 |\n| concatenate_31                      -         (-1, 7, 7, 640)        0         0        0           ?            ? |\n| batch_normalization_36              -         (-1, 7, 7, 640)        0      2560    10.00           0            0 |\n| activation_4                        -         (-1, 7, 7, 640)        0         0        0           ?            ? |\n| global_average_pooling2d            -               (-1, 640)        0         0        0           ?            ? |\n| dense                               -               (-1, 102)        0     65382   255.40           0        65280 |\n+--------------------------------------------------------------------------------------------------------------------+\n| Total                                                          7593984    564518  3132.15  4506808320    199163648 |\n+--------------------------------------------------------------------------------------------------------------------+\n+binary_densenet37 summary-------------------+\n| Total params                      8.16 M   |\n| Trainable params                  8.13 M   |\n| Non-trainable params              31.9 k   |\n| Model size:                       3.06 MB  |\n| Float-32 Equivalent               31.12 MB |\n| Compression Ratio of Memory       0.10     |\n| Number of MACs                    4.71 B   |\n| Ratio of MACs that are binarized  0.9577   |\n+--------------------------------------------+\nDry run: Not starting training!\n'

snapshots['test_compare_model_summary[TrainBinaryDenseNet37Dilated] 1'] = b'+binary_densenet37_dilated stats-------------------------------------------------------------------------------------+\n| Layer                     Input prec.                 Outputs  # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                                 (bit)                              x 1       x 1     (kB)                          |\n+--------------------------------------------------------------------------------------------------------------------+\n| input_1                             -  ((None, 224, 224, 3),)        0         0        0           ?            ? |\n| conv2d                              -      (-1, 112, 112, 64)        0      9408    36.75           0    118013952 |\n| batch_normalization                 -      (-1, 112, 112, 64)        0       256     1.00           0            0 |\n| activation                          -      (-1, 112, 112, 64)        0         0        0           ?            ? |\n| max_pooling2d                       -        (-1, 56, 56, 64)        0         0        0           0            0 |\n| batch_normalization_1               -        (-1, 56, 56, 64)        0       256     1.00           0            0 |\n| quant_conv2d                        1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |\n| concatenate                         -       (-1, 56, 56, 128)        0         0        0           ?            ? |\n| batch_normalization_2               -       (-1, 56, 56, 128)        0       512     2.00           0            0 |\n| quant_conv2d_1                      1        (-1, 56, 56, 64)    73728         0     9.00   231211008            0 |\n| concatenate_1                       -       (-1, 56, 56, 192)        0         0        0           ?            ? |\n| batch_normalization_3               -       (-1, 56, 56, 192)        0       768     3.00           0            0 |\n| quant_conv2d_2                      1        (-1, 56, 56, 64)   110592         0    13.50   346816512            0 |\n| concatenate_2                       -       (-1, 56, 56, 256)        0         0        0           ?            ? |\n| batch_normalization_4               -       (-1, 56, 56, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_3                      1        (-1, 56, 56, 64)   147456         0    18.00   462422016            0 |\n| concatenate_3                       -       (-1, 56, 56, 320)        0         0        0           ?            ? |\n| batch_normalization_5               -       (-1, 56, 56, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_4                      1        (-1, 56, 56, 64)   184320         0    22.50   578027520            0 |\n| concatenate_4                       -       (-1, 56, 56, 384)        0         0        0           ?            ? |\n| batch_normalization_6               -       (-1, 56, 56, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_5                      1        (-1, 56, 56, 64)   221184         0    27.00   693633024            0 |\n| concatenate_5                       -       (-1, 56, 56, 448)        0         0        0           ?            ? |\n| batch_normalization_7               -       (-1, 56, 56, 448)        0      1792     7.00           0            0 |\n| max_pooling2d_1                     -       (-1, 28, 28, 448)        0         0        0           0            0 |\n| activation_1                        -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n| conv2d_1                            -       (-1, 28, 28, 128)        0     57344   224.00           0     44957696 |\n| batch_normalization_8               -       (-1, 28, 28, 128)        0       512     2.00           0            0 |\n| quant_conv2d_6                      1        (-1, 28, 28, 64)    73728         0     9.00    57802752            0 |\n| concatenate_6                       -       (-1, 28, 28, 192)        0         0        0           ?            ? |\n| batch_normalization_9               -       (-1, 28, 28, 192)        0       768     3.00           0            0 |\n| quant_conv2d_7                      1        (-1, 28, 28, 64)   110592         0    13.50    86704128            0 |\n| concatenate_7                       -       (-1, 28, 28, 256)        0         0        0           ?            ? |\n| batch_normalization_10              -       (-1, 28, 28, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_8                      1        (-1, 28, 28, 64)   147456         0    18.00   115605504            0 |\n| concatenate_8                       -       (-1, 28, 28, 320)        0         0        0           ?            ? |\n| batch_normalization_11              -       (-1, 28, 28, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_9                      1        (-1, 28, 28, 64)   184320         0    22.50   144506880            0 |\n| concatenate_9                       -       (-1, 28, 28, 384)        0         0        0           ?            ? |\n| batch_normalization_12              -       (-1, 28, 28, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_10                     1        (-1, 28, 28, 64)   221184         0    27.00   173408256            0 |\n| concatenate_10                      -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n| batch_normalization_13              -       (-1, 28, 28, 448)        0      1792     7.00           0            0 |\n| quant_conv2d_11                     1        (-1, 28, 28, 64)   258048         0    31.50   202309632            0 |\n| concatenate_11                      -       (-1, 28, 28, 512)        0         0        0           ?            ? |\n| batch_normalization_14              -       (-1, 28, 28, 512)        0      2048     8.00           0            0 |\n| quant_conv2d_12                     1        (-1, 28, 28, 64)   294912         0    36.00   231211008            0 |\n| concatenate_12                      -       (-1, 28, 28, 576)        0         0        0           ?            ? |\n| batch_normalization_15              -       (-1, 28, 28, 576)        0      2304     9.00           0            0 |\n| quant_conv2d_13                     1        (-1, 28, 28, 64)   331776         0    40.50   260112384            0 |\n| concatenate_13                      -       (-1, 28, 28, 640)        0         0        0           ?            ? |\n| batch_normalization_16              -       (-1, 28, 28, 640)        0      2560    10.00           0            0 |\n| activation_2                        -       (-1, 28, 28, 640)        0         0        0           ?            ? |\n| conv2d_2                            -       (-1, 28, 28, 192)        0    122880   480.00           0     96337920 |\n| batch_normalization_17              -       (-1, 28, 28, 192)        0       768     3.00           0            0 |\n| quant_conv2d_14                     1        (-1, 28, 28, 64)   110592         0    13.50    86704128            0 |\n| concatenate_14                      -       (-1, 28, 28, 256)        0         0        0           ?            ? |\n| batch_normalization_18              -       (-1, 28, 28, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_15                     1        (-1, 28, 28, 64)   147456         0    18.00   115605504            0 |\n| concatenate_15                      -       (-1, 28, 28, 320)        0         0        0           ?            ? |\n| batch_normalization_19              -       (-1, 28, 28, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_16                     1        (-1, 28, 28, 64)   184320         0    22.50   144506880            0 |\n| concatenate_16                      -       (-1, 28, 28, 384)        0         0        0           ?            ? |\n| batch_normalization_20              -       (-1, 28, 28, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_17                     1        (-1, 28, 28, 64)   221184         0    27.00   173408256            0 |\n| concatenate_17                      -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n| batch_normalization_21              -       (-1, 28, 28, 448)        0      1792     7.00           0            0 |\n| quant_conv2d_18                     1        (-1, 28, 28, 64)   258048         0    31.50   202309632            0 |\n| concatenate_18                      -       (-1, 28, 28, 512)        0         0        0           ?            ? |\n| batch_normalization_22              -       (-1, 28, 28, 512)        0      2048     8.00           0            0 |\n| quant_conv2d_19                     1        (-1, 28, 28, 64)   294912         0    36.00   231211008            0 |\n| concatenate_19                      -       (-1, 28, 28, 576)        0         0        0           ?            ? |\n| batch_normalization_23              -       (-1, 28, 28, 576)        0      2304     9.00           0            0 |\n| quant_conv2d_20                     1        (-1, 28, 28, 64)   331776         0    40.50   260112384            0 |\n| concatenate_20                      -       (-1, 28, 28, 640)        0         0        0           ?            ? |\n| batch_normalization_24              -       (-1, 28, 28, 640)        0      2560    10.00           0            0 |\n| quant_conv2d_21                     1        (-1, 28, 28, 64)   368640         0    45.00   289013760            0 |\n| concatenate_21                      -       (-1, 28, 28, 704)        0         0        0           ?            ? |\n| batch_normalization_25              -       (-1, 28, 28, 704)        0      2816    11.00           0            0 |\n| quant_conv2d_22                     1        (-1, 28, 28, 64)   405504         0    49.50   317915136            0 |\n| concatenate_22                      -       (-1, 28, 28, 768)        0         0        0           ?            ? |\n| batch_normalization_26              -       (-1, 28, 28, 768)        0      3072    12.00           0            0 |\n| quant_conv2d_23                     1        (-1, 28, 28, 64)   442368         0    54.00   346816512            0 |\n| concatenate_23                      -       (-1, 28, 28, 832)        0         0        0           ?            ? |\n| batch_normalization_27              -       (-1, 28, 28, 832)        0      3328    13.00           0            0 |\n| quant_conv2d_24                     1        (-1, 28, 28, 64)   479232         0    58.50   375717888            0 |\n| concatenate_24                      -       (-1, 28, 28, 896)        0         0        0           ?            ? |\n| batch_normalization_28              -       (-1, 28, 28, 896)        0      3584    14.00           0            0 |\n| quant_conv2d_25                     1        (-1, 28, 28, 64)   516096         0    63.00   404619264            0 |\n| concatenate_25                      -       (-1, 28, 28, 960)        0         0        0           ?            ? |\n| batch_normalization_29              -       (-1, 28, 28, 960)        0      3840    15.00           0            0 |\n| activation_3                        -       (-1, 28, 28, 960)        0         0        0           ?            ? |\n| conv2d_3                            -       (-1, 28, 28, 256)        0    245760   960.00           0    192675840 |\n| batch_normalization_30              -       (-1, 28, 28, 256)        0      1024     4.00           0            0 |\n| quant_conv2d_26                     1        (-1, 28, 28, 64)   147456         0    18.00   115605504            0 |\n| concatenate_26                      -       (-1, 28, 28, 320)        0         0        0           ?            ? |\n| batch_normalization_31              -       (-1, 28, 28, 320)        0      1280     5.00           0            0 |\n| quant_conv2d_27                     1        (-1, 28, 28, 64)   184320         0    22.50   144506880            0 |\n| concatenate_27                      -       (-1, 28, 28, 384)        0         0        0           ?            ? |\n| batch_normalization_32              -       (-1, 28, 28, 384)        0      1536     6.00           0            0 |\n| quant_conv2d_28                     1        (-1, 28, 28, 64)   221184         0    27.00   173408256            0 |\n| concatenate_28                      -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n| batch_normalization_33              -       (-1, 28, 28, 448)        0      1792     7.00           0            0 |\n| quant_conv2d_29                     1        (-1, 28, 28, 64)   258048         0    31.50   202309632            0 |\n| concatenate_29                      -       (-1, 28, 28, 512)        0         0        0           ?            ? |\n| batch_normalization_34              -       (-1, 28, 28, 512)        0      2048     8.00           0            0 |\n| quant_conv2d_30                     1        (-1, 28, 28, 64)   294912         0    36.00   231211008            0 |\n| concatenate_30                      -       (-1, 28, 28, 576)        0         0        0           ?            ? |\n| batch_normalization_35              -       (-1, 28, 28, 576)        0      2304     9.00           0            0 |\n| quant_conv2d_31                     1        (-1, 28, 28, 64)   331776         0    40.50   260112384            0 |\n| concatenate_31                      -       (-1, 28, 28, 640)        0         0        0           ?            ? |\n| batch_normalization_36              -       (-1, 28, 28, 640)        0      2560    10.00           0            0 |\n| activation_4                        -       (-1, 28, 28, 640)        0         0        0           ?            ? |\n| global_average_pooling2d            -               (-1, 640)        0         0        0           ?            ? |\n| dense                               -               (-1, 102)        0     65382   255.40           0        65280 |\n+--------------------------------------------------------------------------------------------------------------------+\n| Total                                                          7593984    564518  3132.15  7774470144    452050688 |\n+--------------------------------------------------------------------------------------------------------------------+\n+binary_densenet37_dilated summary-----------+\n| Total params                      8.16 M   |\n| Trainable params                  8.13 M   |\n| Non-trainable params              31.9 k   |\n| Model size:                       3.06 MB  |\n| Float-32 Equivalent               31.12 MB |\n| Compression Ratio of Memory       0.10     |\n| Number of MACs                    8.23 B   |\n| Ratio of MACs that are binarized  0.9450   |\n+--------------------------------------------+\nDry run: Not starting training!\n'

snapshots['test_compare_model_summary[TrainBinaryDenseNet45] 1'] = b'+binary_densenet45 stats----------------------------------------------------------------------------------------------+\n| Layer                     Input prec.                 Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                                 (bit)                               x 1       x 1     (kB)                          |\n+---------------------------------------------------------------------------------------------------------------------+\n| input_1                             -  ((None, 224, 224, 3),)         0         0        0           ?            ? |\n| conv2d                              -      (-1, 112, 112, 64)         0      9408    36.75           0    118013952 |\n| batch_normalization                 -      (-1, 112, 112, 64)         0       256     1.00           0            0 |\n| activation                          -      (-1, 112, 112, 64)         0         0        0           ?            ? |\n| max_pooling2d                       -        (-1, 56, 56, 64)         0         0        0           0            0 |\n| batch_normalization_1               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| quant_conv2d                        1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| concatenate                         -       (-1, 56, 56, 128)         0         0        0           ?            ? |\n| batch_normalization_2               -       (-1, 56, 56, 128)         0       512     2.00           0            0 |\n| quant_conv2d_1                      1        (-1, 56, 56, 64)     73728         0     9.00   231211008            0 |\n| concatenate_1                       -       (-1, 56, 56, 192)         0         0        0           ?            ? |\n| batch_normalization_3               -       (-1, 56, 56, 192)         0       768     3.00           0            0 |\n| quant_conv2d_2                      1        (-1, 56, 56, 64)    110592         0    13.50   346816512            0 |\n| concatenate_2                       -       (-1, 56, 56, 256)         0         0        0           ?            ? |\n| batch_normalization_4               -       (-1, 56, 56, 256)         0      1024     4.00           0            0 |\n| quant_conv2d_3                      1        (-1, 56, 56, 64)    147456         0    18.00   462422016            0 |\n| concatenate_3                       -       (-1, 56, 56, 320)         0         0        0           ?            ? |\n| batch_normalization_5               -       (-1, 56, 56, 320)         0      1280     5.00           0            0 |\n| quant_conv2d_4                      1        (-1, 56, 56, 64)    184320         0    22.50   578027520            0 |\n| concatenate_4                       -       (-1, 56, 56, 384)         0         0        0           ?            ? |\n| batch_normalization_6               -       (-1, 56, 56, 384)         0      1536     6.00           0            0 |\n| quant_conv2d_5                      1        (-1, 56, 56, 64)    221184         0    27.00   693633024            0 |\n| concatenate_5                       -       (-1, 56, 56, 448)         0         0        0           ?            ? |\n| batch_normalization_7               -       (-1, 56, 56, 448)         0      1792     7.00           0            0 |\n| max_pooling2d_1                     -       (-1, 28, 28, 448)         0         0        0           0            0 |\n| activation_1                        -       (-1, 28, 28, 448)         0         0        0           ?            ? |\n| conv2d_1                            -       (-1, 28, 28, 160)         0     71680   280.00           0     56197120 |\n| batch_normalization_8               -       (-1, 28, 28, 160)         0       640     2.50           0            0 |\n| quant_conv2d_6                      1        (-1, 28, 28, 64)     92160         0    11.25    72253440            0 |\n| concatenate_6                       -       (-1, 28, 28, 224)         0         0        0           ?            ? |\n| batch_normalization_9               -       (-1, 28, 28, 224)         0       896     3.50           0            0 |\n| quant_conv2d_7                      1        (-1, 28, 28, 64)    129024         0    15.75   101154816            0 |\n| concatenate_7                       -       (-1, 28, 28, 288)         0         0        0           ?            ? |\n| batch_normalization_10              -       (-1, 28, 28, 288)         0      1152     4.50           0            0 |\n| quant_conv2d_8                      1        (-1, 28, 28, 64)    165888         0    20.25   130056192            0 |\n| concatenate_8                       -       (-1, 28, 28, 352)         0         0        0           ?            ? |\n| batch_normalization_11              -       (-1, 28, 28, 352)         0      1408     5.50           0            0 |\n| quant_conv2d_9                      1        (-1, 28, 28, 64)    202752         0    24.75   158957568            0 |\n| concatenate_9                       -       (-1, 28, 28, 416)         0         0        0           ?            ? |\n| batch_normalization_12              -       (-1, 28, 28, 416)         0      1664     6.50           0            0 |\n| quant_conv2d_10                     1        (-1, 28, 28, 64)    239616         0    29.25   187858944            0 |\n| concatenate_10                      -       (-1, 28, 28, 480)         0         0        0           ?            ? |\n| batch_normalization_13              -       (-1, 28, 28, 480)         0      1920     7.50           0            0 |\n| quant_conv2d_11                     1        (-1, 28, 28, 64)    276480         0    33.75   216760320            0 |\n| concatenate_11                      -       (-1, 28, 28, 544)         0         0        0           ?            ? |\n| batch_normalization_14              -       (-1, 28, 28, 544)         0      2176     8.50           0            0 |\n| quant_conv2d_12                     1        (-1, 28, 28, 64)    313344         0    38.25   245661696            0 |\n| concatenate_12                      -       (-1, 28, 28, 608)         0         0        0           ?            ? |\n| batch_normalization_15              -       (-1, 28, 28, 608)         0      2432     9.50           0            0 |\n| quant_conv2d_13                     1        (-1, 28, 28, 64)    350208         0    42.75   274563072            0 |\n| concatenate_13                      -       (-1, 28, 28, 672)         0         0        0           ?            ? |\n| batch_normalization_16              -       (-1, 28, 28, 672)         0      2688    10.50           0            0 |\n| quant_conv2d_14                     1        (-1, 28, 28, 64)    387072         0    47.25   303464448            0 |\n| concatenate_14                      -       (-1, 28, 28, 736)         0         0        0           ?            ? |\n| batch_normalization_17              -       (-1, 28, 28, 736)         0      2944    11.50           0            0 |\n| quant_conv2d_15                     1        (-1, 28, 28, 64)    423936         0    51.75   332365824            0 |\n| concatenate_15                      -       (-1, 28, 28, 800)         0         0        0           ?            ? |\n| batch_normalization_18              -       (-1, 28, 28, 800)         0      3200    12.50           0            0 |\n| quant_conv2d_16                     1        (-1, 28, 28, 64)    460800         0    56.25   361267200            0 |\n| concatenate_16                      -       (-1, 28, 28, 864)         0         0        0           ?            ? |\n| batch_normalization_19              -       (-1, 28, 28, 864)         0      3456    13.50           0            0 |\n| quant_conv2d_17                     1        (-1, 28, 28, 64)    497664         0    60.75   390168576            0 |\n| concatenate_17                      -       (-1, 28, 28, 928)         0         0        0           ?            ? |\n| batch_normalization_20              -       (-1, 28, 28, 928)         0      3712    14.50           0            0 |\n| max_pooling2d_2                     -       (-1, 14, 14, 928)         0         0        0           0            0 |\n| activation_2                        -       (-1, 14, 14, 928)         0         0        0           ?            ? |\n| conv2d_2                            -       (-1, 14, 14, 288)         0    267264  1044.00           0     52383744 |\n| batch_normalization_21              -       (-1, 14, 14, 288)         0      1152     4.50           0            0 |\n| quant_conv2d_18                     1        (-1, 14, 14, 64)    165888         0    20.25    32514048            0 |\n| concatenate_18                      -       (-1, 14, 14, 352)         0         0        0           ?            ? |\n| batch_normalization_22              -       (-1, 14, 14, 352)         0      1408     5.50           0            0 |\n| quant_conv2d_19                     1        (-1, 14, 14, 64)    202752         0    24.75    39739392            0 |\n| concatenate_19                      -       (-1, 14, 14, 416)         0         0        0           ?            ? |\n| batch_normalization_23              -       (-1, 14, 14, 416)         0      1664     6.50           0            0 |\n| quant_conv2d_20                     1        (-1, 14, 14, 64)    239616         0    29.25    46964736            0 |\n| concatenate_20                      -       (-1, 14, 14, 480)         0         0        0           ?            ? |\n| batch_normalization_24              -       (-1, 14, 14, 480)         0      1920     7.50           0            0 |\n| quant_conv2d_21                     1        (-1, 14, 14, 64)    276480         0    33.75    54190080            0 |\n| concatenate_21                      -       (-1, 14, 14, 544)         0         0        0           ?            ? |\n| batch_normalization_25              -       (-1, 14, 14, 544)         0      2176     8.50           0            0 |\n| quant_conv2d_22                     1        (-1, 14, 14, 64)    313344         0    38.25    61415424            0 |\n| concatenate_22                      -       (-1, 14, 14, 608)         0         0        0           ?            ? |\n| batch_normalization_26              -       (-1, 14, 14, 608)         0      2432     9.50           0            0 |\n| quant_conv2d_23                     1        (-1, 14, 14, 64)    350208         0    42.75    68640768            0 |\n| concatenate_23                      -       (-1, 14, 14, 672)         0         0        0           ?            ? |\n| batch_normalization_27              -       (-1, 14, 14, 672)         0      2688    10.50           0            0 |\n| quant_conv2d_24                     1        (-1, 14, 14, 64)    387072         0    47.25    75866112            0 |\n| concatenate_24                      -       (-1, 14, 14, 736)         0         0        0           ?            ? |\n| batch_normalization_28              -       (-1, 14, 14, 736)         0      2944    11.50           0            0 |\n| quant_conv2d_25                     1        (-1, 14, 14, 64)    423936         0    51.75    83091456            0 |\n| concatenate_25                      -       (-1, 14, 14, 800)         0         0        0           ?            ? |\n| batch_normalization_29              -       (-1, 14, 14, 800)         0      3200    12.50           0            0 |\n| quant_conv2d_26                     1        (-1, 14, 14, 64)    460800         0    56.25    90316800            0 |\n| concatenate_26                      -       (-1, 14, 14, 864)         0         0        0           ?            ? |\n| batch_normalization_30              -       (-1, 14, 14, 864)         0      3456    13.50           0            0 |\n| quant_conv2d_27                     1        (-1, 14, 14, 64)    497664         0    60.75    97542144            0 |\n| concatenate_27                      -       (-1, 14, 14, 928)         0         0        0           ?            ? |\n| batch_normalization_31              -       (-1, 14, 14, 928)         0      3712    14.50           0            0 |\n| quant_conv2d_28                     1        (-1, 14, 14, 64)    534528         0    65.25   104767488            0 |\n| concatenate_28                      -       (-1, 14, 14, 992)         0         0        0           ?            ? |\n| batch_normalization_32              -       (-1, 14, 14, 992)         0      3968    15.50           0            0 |\n| quant_conv2d_29                     1        (-1, 14, 14, 64)    571392         0    69.75   111992832            0 |\n| concatenate_29                      -      (-1, 14, 14, 1056)         0         0        0           ?            ? |\n| batch_normalization_33              -      (-1, 14, 14, 1056)         0      4224    16.50           0            0 |\n| quant_conv2d_30                     1        (-1, 14, 14, 64)    608256         0    74.25   119218176            0 |\n| concatenate_30                      -      (-1, 14, 14, 1120)         0         0        0           ?            ? |\n| batch_normalization_34              -      (-1, 14, 14, 1120)         0      4480    17.50           0            0 |\n| quant_conv2d_31                     1        (-1, 14, 14, 64)    645120         0    78.75   126443520            0 |\n| concatenate_31                      -      (-1, 14, 14, 1184)         0         0        0           ?            ? |\n| batch_normalization_35              -      (-1, 14, 14, 1184)         0      4736    18.50           0            0 |\n| max_pooling2d_3                     -        (-1, 7, 7, 1184)         0         0        0           0            0 |\n| activation_3                        -        (-1, 7, 7, 1184)         0         0        0           ?            ? |\n| conv2d_3                            -         (-1, 7, 7, 288)         0    340992  1332.00           0     16708608 |\n| batch_normalization_36              -         (-1, 7, 7, 288)         0      1152     4.50           0            0 |\n| quant_conv2d_32                     1          (-1, 7, 7, 64)    165888         0    20.25     8128512            0 |\n| concatenate_32                      -         (-1, 7, 7, 352)         0         0        0           ?            ? |\n| batch_normalization_37              -         (-1, 7, 7, 352)         0      1408     5.50           0            0 |\n| quant_conv2d_33                     1          (-1, 7, 7, 64)    202752         0    24.75     9934848            0 |\n| concatenate_33                      -         (-1, 7, 7, 416)         0         0        0           ?            ? |\n| batch_normalization_38              -         (-1, 7, 7, 416)         0      1664     6.50           0            0 |\n| quant_conv2d_34                     1          (-1, 7, 7, 64)    239616         0    29.25    11741184            0 |\n| concatenate_34                      -         (-1, 7, 7, 480)         0         0        0           ?            ? |\n| batch_normalization_39              -         (-1, 7, 7, 480)         0      1920     7.50           0            0 |\n| quant_conv2d_35                     1          (-1, 7, 7, 64)    276480         0    33.75    13547520            0 |\n| concatenate_35                      -         (-1, 7, 7, 544)         0         0        0           ?            ? |\n| batch_normalization_40              -         (-1, 7, 7, 544)         0      2176     8.50           0            0 |\n| quant_conv2d_36                     1          (-1, 7, 7, 64)    313344         0    38.25    15353856            0 |\n| concatenate_36                      -         (-1, 7, 7, 608)         0         0        0           ?            ? |\n| batch_normalization_41              -         (-1, 7, 7, 608)         0      2432     9.50           0            0 |\n| quant_conv2d_37                     1          (-1, 7, 7, 64)    350208         0    42.75    17160192            0 |\n| concatenate_37                      -         (-1, 7, 7, 672)         0         0        0           ?            ? |\n| batch_normalization_42              -         (-1, 7, 7, 672)         0      2688    10.50           0            0 |\n| quant_conv2d_38                     1          (-1, 7, 7, 64)    387072         0    47.25    18966528            0 |\n| concatenate_38                      -         (-1, 7, 7, 736)         0         0        0           ?            ? |\n| batch_normalization_43              -         (-1, 7, 7, 736)         0      2944    11.50           0            0 |\n| quant_conv2d_39                     1          (-1, 7, 7, 64)    423936         0    51.75    20772864            0 |\n| concatenate_39                      -         (-1, 7, 7, 800)         0         0        0           ?            ? |\n| batch_normalization_44              -         (-1, 7, 7, 800)         0      3200    12.50           0            0 |\n| activation_4                        -         (-1, 7, 7, 800)         0         0        0           ?            ? |\n| global_average_pooling2d            -               (-1, 800)         0         0        0           ?            ? |\n| dense                               -               (-1, 102)         0     81702   319.15           0        81600 |\n+---------------------------------------------------------------------------------------------------------------------+\n| Total                                                          12349440    870502  4907.90  6430556160    243385024 |\n+---------------------------------------------------------------------------------------------------------------------+\n+binary_densenet45 summary-------------------+\n| Total params                      13.2 M   |\n| Trainable params                  13.2 M   |\n| Non-trainable params              49.7 k   |\n| Model size:                       4.79 MB  |\n| Float-32 Equivalent               50.43 MB |\n| Compression Ratio of Memory       0.10     |\n| Number of MACs                    6.67 B   |\n| Ratio of MACs that are binarized  0.9635   |\n+--------------------------------------------+\nDry run: Not starting training!\n'

snapshots['test_compare_model_summary[TrainDoReFaNet] 1'] = b'+dorefanet stats---------------------------------------------------------------------------------------------------+\n| Layer                  Input prec.                 Outputs   # 1-bit  # 32-bit   Memory  2-bit MACs  32-bit MACs |\n|                              (bit)                               x 1       x 1     (kB)                          |\n+------------------------------------------------------------------------------------------------------------------+\n| input_1                          -  ((None, 224, 224, 3),)         0         0        0           ?            ? |\n| conv2d                           -        (-1, 54, 54, 96)         0     41568   162.38           0    120932352 |\n| quant_conv2d                     2       (-1, 54, 54, 256)    614400         0    75.00  1791590400            0 |\n| batch_normalization              -       (-1, 54, 54, 256)         0       768     3.00           0            0 |\n| max_pooling2d                    -       (-1, 27, 27, 256)         0         0        0           0            0 |\n| quant_conv2d_1                   2       (-1, 27, 27, 384)    884736         0   108.00   644972544            0 |\n| batch_normalization_1            -       (-1, 27, 27, 384)         0      1152     4.50           0            0 |\n| max_pooling2d_1                  -       (-1, 14, 14, 384)         0         0        0           0            0 |\n| quant_conv2d_2                   2       (-1, 14, 14, 384)   1327104         0   162.00   260112384            0 |\n| batch_normalization_2            -       (-1, 14, 14, 384)         0      1152     4.50           0            0 |\n| quant_conv2d_3                   2       (-1, 14, 14, 256)    884736         0   108.00   173408256            0 |\n| batch_normalization_3            -       (-1, 14, 14, 256)         0       768     3.00           0            0 |\n| max_pooling2d_2                  -         (-1, 6, 6, 256)         0         0        0           0            0 |\n| flatten                          -              (-1, 9216)         0         0        0           0            0 |\n| quant_dense                      2              (-1, 4096)  37748736         0  4608.00    37748736            0 |\n| batch_normalization_4            -              (-1, 4096)         0     12288    48.00           0            0 |\n| quant_dense_1                    2              (-1, 4096)  16777216         0  2048.00    16777216            0 |\n| batch_normalization_5            -              (-1, 4096)         0     12288    48.00           0            0 |\n| activation                       -              (-1, 4096)         0         0        0           ?            ? |\n| dense                            -               (-1, 102)         0    417894  1632.40           0       417792 |\n| activation_1                     -               (-1, 102)         0         0        0           ?            ? |\n+------------------------------------------------------------------------------------------------------------------+\n| Total                                                       58236928    487878  9014.77  2924609536    121350144 |\n+------------------------------------------------------------------------------------------------------------------+\n+dorefanet summary-----------------------------+\n| Total params                       58.7 M    |\n| Trainable params                   58.7 M    |\n| Non-trainable params               18.9 k    |\n| Model size:                        8.80 MB   |\n| Float-32 Equivalent                224.02 MB |\n| Compression Ratio of Memory        0.04      |\n| Number of MACs                     3.05 B    |\n| Ratio of MACs that are ternarized  0.9602    |\n+----------------------------------------------+\nDry run: Not starting training!\n'

snapshots['test_compare_model_summary[TrainBinaryResNetE18] 1'] = b'+binary_resnet_e_18 stats---------------------------------------------------------------------------------------------+\n| Layer                     Input prec.                 Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                                 (bit)                               x 1       x 1     (kB)                          |\n+---------------------------------------------------------------------------------------------------------------------+\n| input_1                             -  ((None, 224, 224, 3),)         0         0        0           ?            ? |\n| conv2d                              -      (-1, 112, 112, 64)         0      9408    36.75           0    118013952 |\n| batch_normalization                 -      (-1, 112, 112, 64)         0       256     1.00           0            0 |\n| activation                          -      (-1, 112, 112, 64)         0         0        0           ?            ? |\n| max_pooling2d                       -        (-1, 56, 56, 64)         0         0        0           0            0 |\n| batch_normalization_1               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| quant_conv2d                        1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| batch_normalization_2               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| add                                 -        (-1, 56, 56, 64)         0         0        0           ?            ? |\n| quant_conv2d_1                      1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| batch_normalization_3               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| add_1                               -        (-1, 56, 56, 64)         0         0        0           ?            ? |\n| quant_conv2d_2                      1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| batch_normalization_4               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| add_2                               -        (-1, 56, 56, 64)         0         0        0           ?            ? |\n| quant_conv2d_3                      1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n| batch_normalization_5               -        (-1, 56, 56, 64)         0       256     1.00           0            0 |\n| add_3                               -        (-1, 56, 56, 64)         0         0        0           ?            ? |\n| average_pooling2d                   -        (-1, 28, 28, 64)         0         0        0           0            0 |\n| quant_conv2d_4                      1       (-1, 28, 28, 128)     73728         0     9.00    57802752            0 |\n| conv2d_1                            -       (-1, 28, 28, 128)         0      8192    32.00           0      6422528 |\n| batch_normalization_7               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| batch_normalization_6               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| add_4                               -       (-1, 28, 28, 128)         0         0        0           ?            ? |\n| quant_conv2d_5                      1       (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n| batch_normalization_8               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| add_5                               -       (-1, 28, 28, 128)         0         0        0           ?            ? |\n| quant_conv2d_6                      1       (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n| batch_normalization_9               -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| add_6                               -       (-1, 28, 28, 128)         0         0        0           ?            ? |\n| quant_conv2d_7                      1       (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n| batch_normalization_10              -       (-1, 28, 28, 128)         0       512     2.00           0            0 |\n| add_7                               -       (-1, 28, 28, 128)         0         0        0           ?            ? |\n| average_pooling2d_1                 -       (-1, 14, 14, 128)         0         0        0           0            0 |\n| quant_conv2d_8                      1       (-1, 14, 14, 256)    294912         0    36.00    57802752            0 |\n| conv2d_2                            -       (-1, 14, 14, 256)         0     32768   128.00           0      6422528 |\n| batch_normalization_12              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| batch_normalization_11              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| add_8                               -       (-1, 14, 14, 256)         0         0        0           ?            ? |\n| quant_conv2d_9                      1       (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n| batch_normalization_13              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| add_9                               -       (-1, 14, 14, 256)         0         0        0           ?            ? |\n| quant_conv2d_10                     1       (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n| batch_normalization_14              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| add_10                              -       (-1, 14, 14, 256)         0         0        0           ?            ? |\n| quant_conv2d_11                     1       (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n| batch_normalization_15              -       (-1, 14, 14, 256)         0      1024     4.00           0            0 |\n| add_11                              -       (-1, 14, 14, 256)         0         0        0           ?            ? |\n| average_pooling2d_2                 -         (-1, 7, 7, 256)         0         0        0           0            0 |\n| quant_conv2d_12                     1         (-1, 7, 7, 512)   1179648         0   144.00    57802752            0 |\n| conv2d_3                            -         (-1, 7, 7, 512)         0    131072   512.00           0      6422528 |\n| batch_normalization_17              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| batch_normalization_16              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| add_12                              -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| quant_conv2d_13                     1         (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n| batch_normalization_18              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| add_13                              -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| quant_conv2d_14                     1         (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n| batch_normalization_19              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| add_14                              -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| quant_conv2d_15                     1         (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n| batch_normalization_20              -         (-1, 7, 7, 512)         0      2048     8.00           0            0 |\n| add_15                              -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| activation_1                        -         (-1, 7, 7, 512)         0         0        0           ?            ? |\n| global_average_pooling2d            -               (-1, 512)         0         0        0           ?            ? |\n| dense                               -               (-1, 102)         0     52326   204.40           0        52224 |\n+---------------------------------------------------------------------------------------------------------------------+\n| Total                                                          10985472    253222  2330.15  1676279808    137333760 |\n+---------------------------------------------------------------------------------------------------------------------+\n+binary_resnet_e_18 summary------------------+\n| Total params                      11.2 M   |\n| Trainable params                  11.2 M   |\n| Non-trainable params              9.73 k   |\n| Model size:                       2.28 MB  |\n| Float-32 Equivalent               42.87 MB |\n| Compression Ratio of Memory       0.05     |\n| Number of MACs                    1.81 B   |\n| Ratio of MACs that are binarized  0.9243   |\n+--------------------------------------------+\nDry run: Not starting training!\n'
